{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essencif.AI Document Intelligence Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDK and libraries installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-documentintelligence==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Utilities and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "document_intelligence_endpoint = os.getenv(\"DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "document_intelligence_key = os.getenv(\"DOCUMENT_INTELLIGENCE_KEY\")\n",
    "storage_connection_string = os.getenv(\"STORAGE_CONNECTION_STRING\")\n",
    "storage_container_name = os.getenv(\"STORAGE_CONTAINER_NAME\")\n",
    "storage_account_name = os.getenv(\"STORAGE_ACCOUNT_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a storage account client to upload blobs (PDFs) to container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_service_client = BlobServiceClient.from_connection_string(storage_connection_string) # creating client to interact with Azure Storage Account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Document Intelligence Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating client to interact with our Document Intelligence Resource Analyse API\n",
    "document_intelligence_client = DocumentIntelligenceClient(\n",
    "    endpoint=document_intelligence_endpoint, credential=AzureKeyCredential(document_intelligence_key)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Parent Combined PDF page-by-page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import os\n",
    "\n",
    "# Input PDF file\n",
    "input_pdf_path = \"./Invoices Upwork.pdf\"  # Change this to your PDF file\n",
    "output_folder = \"output_pages\"  # Folder to store split pages\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Open the input PDF\n",
    "reader = PdfReader(input_pdf_path)\n",
    "\n",
    "# Loop through each page and save it as a separate file\n",
    "for i, page in enumerate(reader.pages):\n",
    "    writer = PdfWriter()\n",
    "    writer.add_page(page)\n",
    "\n",
    "    output_pdf_path = os.path.join(output_folder, f\"{i+1}.pdf\")\n",
    "    with open(output_pdf_path, \"wb\") as output_pdf:\n",
    "        writer.write(output_pdf)\n",
    "    \n",
    "    print(f\"Saved: {output_pdf_path}\")\n",
    "\n",
    "print(\"PDF split completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading single PDF files to the Azure Storage Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(output_folder):\n",
    "    print(file)\n",
    "    blob_client = blob_service_client.get_blob_client(container=storage_container_name, blob=file)\n",
    "    print(\"\\nUploading to Azure Storage as blob:\\n\\t\" + file)\n",
    "\n",
    "    # Upload the created file\n",
    "    upload_file_path = os.path.join(output_folder, file)\n",
    "    with open(file=upload_file_path, mode=\"rb\") as data:\n",
    "        blob_client.upload_blob(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a hashMap to keep track of each invoice clubbed by its page number(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashMap={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a function to keep track of Vendor Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_vendor_name_same(vendor_name_1: str, vendor_name_2: str) -> bool:\n",
    "    \"\"\"\n",
    "    Compares two VendorName strings and returns True if at least one whole string matches,\n",
    "    ignoring case sensitivity.\n",
    "\n",
    "    Args:\n",
    "        vendor_name_1 (str): The first VendorName string.\n",
    "        vendor_name_2 (str): The second VendorName string.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if at least one whole string matches, False otherwise.\n",
    "    \"\"\"\n",
    "    # Normalize the strings by splitting them into individual words or lines\n",
    "    vendor_name_1_parts = set(vendor_name_1.strip().replace(\"\\n\", \" \").lower().split())\n",
    "    vendor_name_2_parts = set(vendor_name_2.strip().replace(\"\\n\", \" \").lower().split())\n",
    "\n",
    "    # Check if there is any intersection between the two sets\n",
    "    return bool(vendor_name_1_parts & vendor_name_2_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a function to keep track of Invoice ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_invoice_id_changed(invoice_id_1: str, invoice_id_2: str) -> bool:\n",
    "    \"\"\"\n",
    "    Compares the numeric parts of two invoice IDs and determines if they are different.\n",
    "\n",
    "    Args:\n",
    "        invoice_id_1 (str): The first invoice ID.\n",
    "        invoice_id_2 (str): The second invoice ID.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the numeric parts are different, False otherwise.\n",
    "    \"\"\"\n",
    "    # Extract numeric parts using regex\n",
    "    numeric_part_1 = re.sub(r'\\D', '', invoice_id_1)\n",
    "    numeric_part_2 = re.sub(r'\\D', '', invoice_id_2)\n",
    "\n",
    "    return numeric_part_1 != numeric_part_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Function to analyse a PDF file using Azure Doc Intelligence's Analyze API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_intelligence(blob_url, page_number):\n",
    "    \"\"\"Process a single-page PDF and extract invoice details using Azure Document Intelligence.\"\"\"\n",
    "    try:\n",
    "        global current_vendor_name  # Declare global to track VendorName across pages\n",
    "        \n",
    "        global current_invoice_id  # Declare global to track InvoiceId across pages\n",
    "         \n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-invoice\", AnalyzeDocumentRequest(url_source=blob_url),\n",
    "            \n",
    "        )\n",
    "        invoices = poller.result()\n",
    "\n",
    "        fields_to_extract = [\"InvoiceId\", \"VendorName\", \"VendorAddressRecipient\", \"InvoiceTotal\", \"CustomerName\", \"InvoiceDate\", \"TotalTax\"] #our principal fields of interest\n",
    "        # Initialize flags to check if fields are found\n",
    "        found_invoice_id = False\n",
    "        found_invoice_total = False\n",
    "        current_page_vendor_name = None\n",
    "        found_customer_name = False\n",
    "        current_page_invoice_id = None\n",
    "        \n",
    "        \n",
    "        # Check if the page contains any of the fields we are interested in\n",
    "\n",
    "        for invoice in invoices.documents:\n",
    "            \n",
    "            print(f\"Page {page_number} fields: {invoice.fields.keys()}\")\n",
    "            for field in fields_to_extract:\n",
    "                field_value = invoice.fields.get(field)\n",
    "                if field_value:\n",
    "                    if field == \"InvoiceId\":\n",
    "                        found_invoice_id = True\n",
    "                        current_page_invoice_id = field_value.value_string\n",
    "                        print(\"page number:{}, field: {},  field_value: {}\".format(page_number,field, field_value))  # Print the value of InvoiceId\n",
    "                    \n",
    "                    if field == \"VendorName\":\n",
    "                        found_invoice_id = True\n",
    "                        print(\"page number:{}, field: {}, field_value: {} \".format(page_number,field,field_value))  # Print the value of VendorName\n",
    "                    \n",
    "                    if field == \"VendorAddressRecipient\":\n",
    "                        found_invoice_id = True\n",
    "                        print(\"page number:{}, field: {}, field_value: {} \".format(page_number,field,field_value))\n",
    "                        \n",
    "                    if field==\"InvoiceTotal\" and field_value.confidence >= 0.5:\n",
    "                        # Check if confidence is above 0.5 before considering it valid\n",
    "                        found_invoice_total = True\n",
    "                        print(\"page number:{}, field: {}, field_value: {} \".format(page_number,field,field_value))\n",
    "                    \n",
    "                    if field == \"CustomerName\":\n",
    "                        found_customer_name = True\n",
    "                        print(\"page number:{}, field: {}, field_value: {} \".format(page_number,field,field_value))\n",
    "                        \n",
    "                    if field == \"InvoiceDate\":\n",
    "                        found_invoice_id = True\n",
    "                        print(\"page number:{}, field: {}, field_value: {} \".format(page_number,field,field_value))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if field == \"TotalTax\":\n",
    "                        found_invoice_total = True\n",
    "                        print(\"page number:{}, field: {}, field_value: {} \".format(page_number,field,field_value))\n",
    "                        \n",
    "                    if field==\"VendorName\":\n",
    "                        \n",
    "                        current_page_vendor_name = field_value.value_string\n",
    "                        print(\"page number:{}, field: {}, field_value: {} \".format(page_number,field,field_value))\n",
    "                    \n",
    "\n",
    "                    # If both InvoiceId and SubTotal are found on the same page\n",
    "                \n",
    "        if current_page_vendor_name:\n",
    "            if current_vendor_name and is_vendor_name_same(current_page_vendor_name, current_vendor_name) is not True:\n",
    "                print(f\"Vendor name changed from {current_vendor_name} to {current_page_vendor_name} on page {page_number}.\")\n",
    "                current_vendor_name = current_page_vendor_name  #Update the global variable\n",
    "                return \"VendorNameChanged\"\n",
    "            \n",
    "            #Update the global variable if its the first page\n",
    "            current_vendor_name = current_page_vendor_name  # Update the local variable\n",
    "        \n",
    "        if current_page_invoice_id:\n",
    "            if current_invoice_id and is_invoice_id_changed(current_page_invoice_id, current_invoice_id) is True:\n",
    "                print(f\"InvoiceId changed from {current_invoice_id} to {current_page_invoice_id} on page {page_number}.\")\n",
    "                current_invoice_id = current_page_invoice_id #Update the global variable\n",
    "                return \"InvoiceIdChanged\"\n",
    "            # Update the global variable if its the first page \n",
    "            current_invoice_id = current_page_invoice_id  #Update the global variable\n",
    "            \n",
    "            \n",
    "        # If only InvoiceId is found\n",
    "        if found_customer_name:\n",
    "            hashMap[page_number] = \"InvoiceId\"\n",
    "            print(\"InvoiceId\")\n",
    "            return \"InvoiceId\"\n",
    "        \n",
    "        if found_invoice_total:\n",
    "            hashMap[page_number] = \"InvoiceTotal\"\n",
    "            print(\"InvoiceTotal\")\n",
    "            return \"InvoiceTotal\"\n",
    "        \n",
    "        # If no relevant fields are found, mark as \"child page\"\n",
    "        hashMap[page_number] = \"child page\"\n",
    "        print(\"page number : {} child page\".format(page_number))\n",
    "        return \"child page\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing page {page_number}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to combine multiple PDF files into a single PDF file - for creating a consolidated invoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_from_pages(input_pdf: str, output_pdf: str, pages: list):\n",
    "    \"\"\"\n",
    "    Creates a new PDF containing only the specified pages from the input PDF.\n",
    "\n",
    "    :param input_pdf: Path to the original multi-page PDF.\n",
    "    :param output_pdf: Path to save the new PDF.\n",
    "    :param pages: List of page numbers (1-based index) to include in the new PDF.\n",
    "    \"\"\"\n",
    "    if not pages:\n",
    "        print(\"No pages specified for creating the PDF.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        reader = PdfReader(input_pdf)\n",
    "        writer = PdfWriter()\n",
    "\n",
    "        for page_num in pages:\n",
    "            if 1 <= page_num <= len(reader.pages):\n",
    "                writer.add_page(reader.pages[page_num - 1])  # Convert 1-based to 0-based index\n",
    "            else:\n",
    "                print(f\"Invalid page number: {page_num}\")\n",
    "\n",
    "        # Ensure the output directory exists\n",
    "        output_dir = \"output_files\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        with open(os.path.join(output_dir, output_pdf), \"wb\") as out_file:\n",
    "            writer.write(out_file)\n",
    "\n",
    "        print(f\"New PDF created: {output_pdf}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating PDF: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reads a multi-page PDF and sends to Document Intelligence for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path: str):\n",
    "    \"\"\"Reads a multi-page PDF and sends each page separately to Azure Document Intelligence.\"\"\"\n",
    "    try:\n",
    "        pdf_reader = PdfReader(pdf_path)\n",
    "        hashMap.clear()  # Clear the hashMap before processing\n",
    "        invoiceID = None\n",
    "        pageList = []  # To store all pages in the hashMap of the current invoice to be consolidated into a single PDF\n",
    "        count = 1 #for naming the output files\n",
    "        \n",
    "        global current_vendor_name\n",
    "        current_vendor_name = None  # Initialize the current VendorName\n",
    "        \n",
    "        global current_invoice_id\n",
    "        current_invoice_id = None  # Initialize the current InvoiceId\n",
    "        \n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            # Generate the blob URL for the current page\n",
    "            blob_url = f\"https://{storage_account_name}.blob.core.windows.net/{storage_container_name}/{page_num + 1}.pdf\"\n",
    "\n",
    "            # Call Azure Document Intelligence for this page\n",
    "            result = document_intelligence(blob_url, page_num + 1)  # Use 1-based page index\n",
    "            \n",
    "            if result == \"VendorNameChanged\":\n",
    "                # Finalize the current invoice (exclude the current page)\n",
    "                if pageList:\n",
    "                    create_pdf_from_pages(pdf_path, f\"output_{count}.pdf\", pageList)\n",
    "                    print(f\"VendorName changed: New PDF created: output_{count}.pdf with pages: {pageList}\")\n",
    "                    count += 1\n",
    "                    pageList = []  # Reset the page list for the next invoice\n",
    "\n",
    "                # Clear the hashMap for the new invoice\n",
    "                hashMap.clear()\n",
    "                \n",
    "                # Process the current page again\n",
    "                result = document_intelligence(blob_url, page_num+1) #reprocess the current page\n",
    "                    \n",
    "\n",
    "            if result == \"InvoiceTotal\":\n",
    "                # Check if we have both \"InvoiceId\" and \"InvoiceTotal\" in the hashMap\n",
    "                if \"InvoiceId\" in hashMap.values() and \"InvoiceTotal\" in hashMap.values():\n",
    "                    pageList = list(hashMap.keys())  # Collect all pages in hashMap\n",
    "                    pageList.sort()  # Ensure pages are in ascending order\n",
    "\n",
    "                    # Find the page with \"InvoiceId\" and set it as the invoiceID\n",
    "                    for page, field in hashMap.items():\n",
    "                        if field == \"InvoiceId\":\n",
    "                            invoiceID = page\n",
    "                            break\n",
    "\n",
    "                    # Create the output PDF for the current invoice\n",
    "                    create_pdf_from_pages(pdf_path, f\"output_{count}.pdf\", pageList)\n",
    "                    print(f\"pageList: {pageList}\")\n",
    "                    print(f\"New PDF created: output_{count}.pdf\")\n",
    "                    print(f\"hashMap: {hashMap}\")\n",
    "                    count+=1\n",
    "                    # Clear the hashMap and pageList for the next invoice\n",
    "                    hashMap.clear()\n",
    "                    pageList = []\n",
    "                    continue\n",
    "            \n",
    "            if result==\"InvoiceIdChanged\":\n",
    "                # Finalize the current invoice (exclude the current page)\n",
    "                if pageList:\n",
    "                    create_pdf_from_pages(pdf_path, f\"output_{count}.pdf\", pageList)\n",
    "                    print(f\"Invoice ID changed: New PDF created: output_{count}.pdf with pages: {pageList}\")\n",
    "                    count += 1\n",
    "                    pageList = []  # Reset the page list for the next invoice\n",
    "                \n",
    "                # Clear the hashMap for the new invoice\n",
    "                hashMap.clear()\n",
    "                \n",
    "                # Process the current page again\n",
    "                result = document_intelligence(blob_url, page_num+1) #reprocess the current page\n",
    "                \n",
    "            \n",
    "            # Add current page to the pageList\n",
    "            pageList.append(page_num + 1)  # Use 1-based page index\n",
    "            \n",
    "            \n",
    "                \n",
    "        # Finalize the last invoice if any pages are left in pageList\n",
    "        if pageList:\n",
    "            create_pdf_from_pages(pdf_path, f\"output_{count}.pdf\", pageList)\n",
    "            print(f\"Remaining pages consolidated: New PDF created: output_{count}.pdf with pages: {pageList}\")\n",
    "            \n",
    "        if not pageList:\n",
    "            print(\"No valid invoice data found in the PDF.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the PDF: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_pdf(input_pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading consolidated PDFs to Azure Storage Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(\"output_files\"):\n",
    "    print(file)\n",
    "    blob_client = blob_service_client.get_blob_client(container=storage_container_name, blob=file)\n",
    "    print(\"\\nUploading to Azure Storage as blob:\\n\\t\" + file)\n",
    "\n",
    "    # Upload the created file\n",
    "    upload_file_path = os.path.join(\"output_files\", file)\n",
    "    with open(file=upload_file_path, mode=\"rb\") as data:\n",
    "        blob_client.upload_blob(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to call the Prompt FLow endpoint with the consolidated invoice as the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "def call_prompt_flow_endpoint(url, file_path):\n",
    "    # Ensure the parent folder 'final_output' exists\n",
    "    parent_folder = \"final_output\"\n",
    "    os.makedirs(parent_folder, exist_ok=True)\n",
    "\n",
    "    # Extract the file name without extension from file_path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_stem, file_ext = os.path.splitext(file_name)\n",
    "    \n",
    "    # Create a subfolder named after the file (without extension)\n",
    "    sub_folder = os.path.join(parent_folder, file_stem)\n",
    "    os.makedirs(sub_folder, exist_ok=True)\n",
    "\n",
    "    # Request data\n",
    "    data = {\"url\": url}\n",
    "    body = str.encode(json.dumps(data))\n",
    "\n",
    "    # Load API details from environment variables\n",
    "    url_endpoint = os.getenv(\"PROMPT_FLOW_ENDPOINT\")\n",
    "    api_key = os.getenv(\"PROMPT_FLOW_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/json',\n",
    "        'Authorization': 'Bearer ' + api_key\n",
    "    }\n",
    "\n",
    "    req = urllib.request.Request(url_endpoint, body, headers)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "        result = response.read()\n",
    "        print(result)\n",
    "\n",
    "        # Decode and parse JSON\n",
    "        response_json = json.loads(result.decode(\"utf-8\"))\n",
    "\n",
    "        # Extract markdown text and JSON structure\n",
    "        markdown_text = response_json[\"output\"][\"markdown_text\"]\n",
    "        json_struct = response_json[\"output\"][\"json_struct\"]\n",
    "\n",
    "        # Save Markdown file\n",
    "        md_file_path = os.path.join(sub_folder, f\"{file_stem}.md\")\n",
    "        with open(md_file_path, \"w\", encoding=\"utf-8\") as md_file:\n",
    "            md_file.write(markdown_text)\n",
    "\n",
    "        # Save JSON file\n",
    "        json_file_path = os.path.join(sub_folder, f\"{file_stem}.json\")\n",
    "        with open(json_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(json_struct, json_file, indent=4)\n",
    "\n",
    "        # Copy the original PDF file to the subfolder\n",
    "        pdf_destination_path = os.path.join(sub_folder, file_name)\n",
    "        shutil.copy(file_path, pdf_destination_path)\n",
    "\n",
    "        # Create a ZIP archive of the subfolder\n",
    "        zip_file_path = os.path.join(parent_folder, f\"{file_stem}.zip\")\n",
    "        shutil.make_archive(zip_file_path.replace(\".zip\", \"\"), 'zip', sub_folder)\n",
    "\n",
    "        print(f\"Files saved in: {sub_folder}\")\n",
    "        print(f\"- {md_file_path}\")\n",
    "        print(f\"- {json_file_path}\")\n",
    "        print(f\"- {pdf_destination_path}\")\n",
    "        print(f\"Zipped Folder: {zip_file_path}\")\n",
    "\n",
    "    except urllib.error.HTTPError as error:\n",
    "        print(\"The request failed with status code: \" + str(error.code))\n",
    "        print(error.info())\n",
    "        print(error.read().decode(\"utf8\", 'ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(\"output_files\"):\n",
    "    blob_url = f\"https://{storage_account_name}.blob.core.windows.net/{storage_container_name}/{file}\"\n",
    "    print(blob_url)\n",
    "    call_prompt_flow_endpoint(blob_url, file_path=\"output_files/\"+file)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
