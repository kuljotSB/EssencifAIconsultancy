{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essencif.AI Doucument Intelligence Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDK and libraries installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-documentintelligence==1.0.0b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Utilities and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "document_intelligence_endpoint = os.getenv(\"DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "document_intelligence_key = os.getenv(\"DOCUMENT_INTELLIGENCE_KEY\")\n",
    "storage_connection_string = os.getenv(\"STORAGE_CONNECTION_STRING\")\n",
    "storage_container_name = os.getenv(\"STORAGE_CONTAINER_NAME\")\n",
    "storage_account_name = os.getenv(\"STORAGE_ACCOUNT_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a storage account client to upload blobs (PDFs) to container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_service_client = BlobServiceClient.from_connection_string(storage_connection_string) # creating client to interact with Azure Storage Account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Document Intelligence Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating client to interact with our Document Intelligence Resource Analyse API\n",
    "document_intelligence_client = DocumentIntelligenceClient(\n",
    "    endpoint=document_intelligence_endpoint, credential=AzureKeyCredential(document_intelligence_key)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Parent Combined PDF page-by-page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: output_pages\\1.pdf\n",
      "Saved: output_pages\\2.pdf\n",
      "Saved: output_pages\\3.pdf\n",
      "Saved: output_pages\\4.pdf\n",
      "Saved: output_pages\\5.pdf\n",
      "Saved: output_pages\\6.pdf\n",
      "Saved: output_pages\\7.pdf\n",
      "Saved: output_pages\\8.pdf\n",
      "Saved: output_pages\\9.pdf\n",
      "Saved: output_pages\\10.pdf\n",
      "PDF split completed!\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import os\n",
    "\n",
    "# Input PDF file\n",
    "input_pdf_path = \"./finalised_invoice_dataset_disorganised.pdf\"  # Change this to your PDF file\n",
    "output_folder = \"output_pages\"  # Folder to store split pages\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Open the input PDF\n",
    "reader = PdfReader(input_pdf_path)\n",
    "\n",
    "# Loop through each page and save it as a separate file\n",
    "for i, page in enumerate(reader.pages):\n",
    "    writer = PdfWriter()\n",
    "    writer.add_page(page)\n",
    "\n",
    "    output_pdf_path = os.path.join(output_folder, f\"{i+1}.pdf\")\n",
    "    with open(output_pdf_path, \"wb\") as output_pdf:\n",
    "        writer.write(output_pdf)\n",
    "    \n",
    "    print(f\"Saved: {output_pdf_path}\")\n",
    "\n",
    "print(\"PDF split completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading single PDF files to the Azure Storage Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(output_folder):\n",
    "    print(file)\n",
    "    blob_client = blob_service_client.get_blob_client(container=storage_container_name, blob=file)\n",
    "    print(\"\\nUploading to Azure Storage as blob:\\n\\t\" + file)\n",
    "\n",
    "    # Upload the created file\n",
    "    upload_file_path = os.path.join(output_folder, file)\n",
    "    with open(file=upload_file_path, mode=\"rb\") as data:\n",
    "        blob_client.upload_blob(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a hashMap to keep track of each invoice clubbed by its page number(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashMap={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Function to analyse a PDF file using Azure Doc Intelligence's Analyze API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_intelligence(blob_url, page_number):\n",
    "    \"\"\"Process a single-page PDF and extract invoice details using Azure Document Intelligence.\"\"\"\n",
    "    try:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-invoice\", AnalyzeDocumentRequest(url_source=blob_url)\n",
    "        )\n",
    "        invoices = poller.result()\n",
    "\n",
    "        fields_to_extract = [\"InvoiceId\", \"SubTotal\", \"AmountDue\"] #Our principal fields of comparison to decide whether a page is start, child or end\n",
    "        for invoice in invoices.documents:\n",
    "            for field in fields_to_extract:\n",
    "                field_value = invoice.fields.get(field)\n",
    "                if field_value:\n",
    "                    hashMap[page_number] = field\n",
    "                    print(field)\n",
    "                    if field==\"InvoiceId\" and (\"SubTotal\" in hashMap.values() or \"AmountDue\" in hashMap.values()):\n",
    "                     return \"SubTotal\" # return SubTotal to signify having reached the end page of the invoice, meaning the invoices are arranged in reverse order\n",
    "                    else:\n",
    "                        return field\n",
    "\n",
    "        # If no relevant fields are found, mark as \"child page\"\n",
    "        hashMap[page_number] = \"child page\"\n",
    "        print(\"child page\")\n",
    "        return \"child page\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing page {page_number}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to combine multiple PDF files into a single PDF file - for creating a consolidated invoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_from_pages(input_pdf: str, output_pdf: str, pages: list):\n",
    "    \"\"\"\n",
    "    Creates a new PDF containing only the specified pages from the input PDF.\n",
    "\n",
    "    :param input_pdf: Path to the original multi-page PDF.\n",
    "    :param output_pdf: Path to save the new PDF.\n",
    "    :param pages: List of page numbers (1-based index) to include in the new PDF.\n",
    "    \"\"\"\n",
    "    if not pages:\n",
    "        print(\"No pages specified for creating the PDF.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        reader = PdfReader(input_pdf)\n",
    "        writer = PdfWriter()\n",
    "\n",
    "        for page_num in pages:\n",
    "            if 1 <= page_num <= len(reader.pages):\n",
    "                writer.add_page(reader.pages[page_num - 1])  # Convert 1-based to 0-based index\n",
    "            else:\n",
    "                print(f\"Invalid page number: {page_num}\")\n",
    "\n",
    "        # Ensure the output directory exists\n",
    "        output_dir = \"output_files\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        with open(os.path.join(output_dir, output_pdf), \"wb\") as out_file:\n",
    "            writer.write(out_file)\n",
    "\n",
    "        print(f\"New PDF created: {output_pdf}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating PDF: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reads a multi-page PDF and sends to Document Intelligence for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path: str):\n",
    "    \"\"\"Reads a multi-page PDF and sends each page separately to Azure Document Intelligence.\"\"\"\n",
    "    try:\n",
    "        pdf_reader = PdfReader(pdf_path)\n",
    "        hashMap.clear()  # Clear the hashMap before processing\n",
    "        invoiceID = None\n",
    "        pageList = [] #to store all pages in the hashMap of the current invoice to be consolidated into a single PDF\n",
    "\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            # Generate the blob URL for the current page\n",
    "            blob_url = f\"https://{storage_account_name}.blob.core.windows.net/{storage_container_name}/{page_num + 1}.pdf\"\n",
    "\n",
    "            # Call Azure Document Intelligence for this page\n",
    "            result = document_intelligence(blob_url, page_num + 1)  # Use 1-based page index\n",
    "            if result in {\"SubTotal\", \"AmountDue\"} and \"InvoiceId\" in hashMap.values():\n",
    "                pageList = list(hashMap.keys())  # Collect all pages in hashMap\n",
    "                if \"InvoiceId\" in hashMap.values():\n",
    "                    # Find the page with \"InvoiceID\" and set it as the invoiceID\n",
    "                    for page, field in hashMap.items():\n",
    "                        print(\"field: {}, page: {}\".format(field, page))\n",
    "                        if field == \"InvoiceId\":\n",
    "                            invoiceID = page\n",
    "                            break\n",
    "\n",
    "                # Reverse the page list and create the output PDF\n",
    "                if invoiceID>pageList[0]:\n",
    "                 pageList.sort(reverse=True)\n",
    "                print(\"pageList:\", pageList)\n",
    "                create_pdf_from_pages(pdf_path, f\"output_{invoiceID}.pdf\", pageList)\n",
    "                print(\"hashMap:\", hashMap)\n",
    "                hashMap.clear()  # Clear the hashMap for the next invoice\n",
    "               \n",
    "\n",
    "        if not pageList:\n",
    "            print(\"No valid invoice data found in the PDF.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the PDF: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_pdf(input_pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading consolidated PDFs to Azure Storage Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(\"output_files\"):\n",
    "    print(file)\n",
    "    blob_client = blob_service_client.get_blob_client(container=storage_container_name, blob=file)\n",
    "    print(\"\\nUploading to Azure Storage as blob:\\n\\t\" + file)\n",
    "\n",
    "    # Upload the created file\n",
    "    upload_file_path = os.path.join(\"output_files\", file)\n",
    "    with open(file=upload_file_path, mode=\"rb\") as data:\n",
    "        blob_client.upload_blob(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to call the Prompt FLow endpoint with the consolidated invoice as the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "def call_prompt_flow_endpoint(url, file_path):\n",
    "    # Ensure the parent folder 'final_output' exists\n",
    "    parent_folder = \"final_output\"\n",
    "    os.makedirs(parent_folder, exist_ok=True)\n",
    "\n",
    "    # Extract the file name without extension from file_path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_stem, file_ext = os.path.splitext(file_name)\n",
    "    \n",
    "    # Create a subfolder named after the file (without extension)\n",
    "    sub_folder = os.path.join(parent_folder, file_stem)\n",
    "    os.makedirs(sub_folder, exist_ok=True)\n",
    "\n",
    "    # Request data\n",
    "    data = {\"url\": url}\n",
    "    body = str.encode(json.dumps(data))\n",
    "\n",
    "    # Load API details from environment variables\n",
    "    url_endpoint = os.getenv(\"PROMPT_FLOW_ENDPOINT\")\n",
    "    api_key = os.getenv(\"PROMPT_FLOW_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/json',\n",
    "        'Authorization': 'Bearer ' + api_key\n",
    "    }\n",
    "\n",
    "    req = urllib.request.Request(url_endpoint, body, headers)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "        result = response.read()\n",
    "        print(result)\n",
    "\n",
    "        # Decode and parse JSON\n",
    "        response_json = json.loads(result.decode(\"utf-8\"))\n",
    "\n",
    "        # Extract markdown text and JSON structure\n",
    "        markdown_text = response_json[\"output\"][\"markdown_text\"]\n",
    "        json_struct = response_json[\"output\"][\"json_struct\"]\n",
    "\n",
    "        # Save Markdown file\n",
    "        md_file_path = os.path.join(sub_folder, f\"{file_stem}.md\")\n",
    "        with open(md_file_path, \"w\", encoding=\"utf-8\") as md_file:\n",
    "            md_file.write(markdown_text)\n",
    "\n",
    "        # Save JSON file\n",
    "        json_file_path = os.path.join(sub_folder, f\"{file_stem}.json\")\n",
    "        with open(json_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(json_struct, json_file, indent=4)\n",
    "\n",
    "        # Copy the original PDF file to the subfolder\n",
    "        pdf_destination_path = os.path.join(sub_folder, file_name)\n",
    "        shutil.copy(file_path, pdf_destination_path)\n",
    "\n",
    "        # Create a ZIP archive of the subfolder\n",
    "        zip_file_path = os.path.join(parent_folder, f\"{file_stem}.zip\")\n",
    "        shutil.make_archive(zip_file_path.replace(\".zip\", \"\"), 'zip', sub_folder)\n",
    "\n",
    "        print(f\"Files saved in: {sub_folder}\")\n",
    "        print(f\"- {md_file_path}\")\n",
    "        print(f\"- {json_file_path}\")\n",
    "        print(f\"- {pdf_destination_path}\")\n",
    "        print(f\"Zipped Folder: {zip_file_path}\")\n",
    "\n",
    "    except urllib.error.HTTPError as error:\n",
    "        print(\"The request failed with status code: \" + str(error.code))\n",
    "        print(error.info())\n",
    "        print(error.read().decode(\"utf8\", 'ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(\"output_files\"):\n",
    "    blob_url = f\"https://{storage_account_name}.blob.core.windows.net/{storage_container_name}/{file}\"\n",
    "    print(blob_url)\n",
    "    call_prompt_flow_endpoint(blob_url, file_path=\"output_files/\"+file)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
